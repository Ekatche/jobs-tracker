import asyncio
import os
from datetime import datetime, timezone
from app.services.job_offers import get_job_offers_from_query
from app.database import get_database
import logging


# ‚úÖ Configuration intelligente des logs
def setup_logger():
    """Configure le logger selon l'environnement"""
    env = os.getenv("ENVIRONMENT", "development")

    if env == "production":
        level = logging.WARNING  # ‚úÖ Seulement WARNING et ERROR en prod
    elif env == "airflow":
        level = logging.INFO  # ‚úÖ INFO pour Airflow (monitoring)
    else:
        level = logging.DEBUG  # ‚úÖ DEBUG pour d√©veloppement local

    logger = logging.getLogger(__name__)
    logger.setLevel(level)
    return logger


logger = setup_logger()


async def collect_and_save_offers(query: str):
    """Collecte et sauvegarde les offres d'emploi - Version optimis√©e logs"""
    try:
        logger.info(f"üöÄ Collecte d√©mar√©e: {query}")  # ‚úÖ Log essentiel uniquement

        # V√©rifications
        required_env_vars = ["OPENAI_API_KEY", "TAVILY_API_KEY"]
        missing_vars = [var for var in required_env_vars if not os.getenv(var)]

        if missing_vars:
            raise ValueError(f"Variables manquantes: {', '.join(missing_vars)}")

        # ‚úÖ Timeout interne pour √©viter les blocages
        try:
            offers = await asyncio.wait_for(
                get_job_offers_from_query(query), timeout=900  # 15 minutes max
            )
        except asyncio.TimeoutError:
            logger.error("‚è∞ Timeout lors de la collecte des offres")
            raise Exception("Timeout de collecte d√©pass√©")

        if not isinstance(offers, list):
            raise TypeError(f"Format invalide: {type(offers)}")

        logger.info(f"üìä {len(offers)} offres r√©cup√©r√©es")  # ‚úÖ M√©trique importante

        if not offers:
            logger.warning("‚ö†Ô∏è Aucune offre trouv√©e")
            return {"saved": 0, "updated": 0}

        # ‚úÖ Traitement avec logs r√©duits
        enriched_offers = []
        invalid_count = 0

        for i, offer in enumerate(offers):
            try:
                if not isinstance(offer, dict):
                    invalid_count += 1
                    continue

                url = offer.get("url") or offer.get("source_url") or ""

                # ‚úÖ Accepter m√™me sans URL valide (ne pas skip syst√©matiquement)
                if url and not url.startswith("http"):
                    url = None  # Standardiser plut√¥t que rejeter

                enriched_offer = {
                    "poste": str(offer.get("poste") or "Poste non sp√©cifi√©"),
                    "entreprise": str(
                        offer.get("entreprise") or "Entreprise non sp√©cifi√©e"
                    ),
                    "localisation": offer.get("localisation"),
                    "date": offer.get("date"),
                    "url": url,
                    "source_url": offer.get("source_url"),
                    "updated_at": datetime.now(timezone.utc),
                    "source_query": query,
                    "offer_id": str(offer.get("id", "")),
                    "raw_data": offer,
                }
                enriched_offers.append(enriched_offer)

            except Exception as e:
                invalid_count += 1
                logger.error(f"üí• Erreur Enrichissement: {e}")
                # ‚úÖ Log group√© plut√¥t qu'individuel
                continue

        # ‚úÖ Log de r√©sum√© plut√¥t que d√©taill√©
        if invalid_count > 0:
            logger.warning(f"‚ö†Ô∏è {invalid_count} offres invalides ignor√©es")

        if not enriched_offers:
            logger.warning("‚ö†Ô∏è Aucune offre valide apr√®s enrichissement")
            return {"saved": 0, "updated": 0}

        # logger.info(f"‚úÖ {len(enriched_offers)} offres enrichies")

        # ‚úÖ Sauvegarde optimis√©e
        db = await get_database()
        collection = db["job_offers"]

        saved_count = 0
        updated_count = 0
        error_count = 0

        for offer in enriched_offers:
            try:
                # ‚úÖ Filtre intelligent pour √©viter doublons
                if offer.get("url"):
                    query_filter = {"url": offer["url"]}
                else:
                    query_filter = {
                        "poste": offer["poste"],
                        "entreprise": offer["entreprise"],
                        "localisation": offer["localisation"],
                    }

                # ‚úÖ Correction du conflit created_at
                current_time = datetime.now(timezone.utc)

                result = await collection.update_one(
                    query_filter,
                    {
                        "$set": {
                            "poste": offer["poste"],
                            "entreprise": offer["entreprise"],
                            "localisation": offer["localisation"],
                            "date": offer["date"],
                            "url": offer["url"],
                            "source_url": offer["source_url"],
                            "updated_at": current_time,
                            "source_query": offer["source_query"],
                            "offer_id": offer["offer_id"],
                            "raw_data": offer["raw_data"],
                        },
                        "$setOnInsert": {"created_at": current_time},
                    },
                    upsert=True,
                )

                if result.upserted_id:
                    saved_count += 1
                else:
                    updated_count += 1

            except Exception as e:
                error_count += 1
                logger.error(f"üí• Erreur Enrichissement : {e}")
                continue

        # ‚úÖ Log final de r√©sum√© uniquement
        logger.info(f"üéØ Termin√©: {saved_count} cr√©√©es, {updated_count} mises √† jour")

        if error_count > 0:
            logger.warning(f"‚ö†Ô∏è {error_count} erreurs de sauvegarde")

        return {"saved": saved_count, "updated": updated_count}

    except Exception as e:
        logger.error(f"üí• Erreur collecte: {e}")
        raise


def collect_offers_sync(query: str):
    """Version synchrone pour Airflow"""
    try:
        # ‚úÖ D√©finir l'environnement pour Airflow
        os.environ.setdefault("ENVIRONMENT", "airflow")
        # ‚úÖ Utiliser un event loop avec timeout
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            return loop.run_until_complete(
                asyncio.wait_for(
                    collect_and_save_offers(query), timeout=900  # 10 minutes max
                )
            )
        finally:
            loop.close()
    except Exception as e:
        logger.error(f"üí• Erreur sync: {e}")
        raise
